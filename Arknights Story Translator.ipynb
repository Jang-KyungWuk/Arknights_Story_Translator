{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arknights Story Translator v3.4 commentary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWPsTM04ZtdZ9j5TkHBZPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jang-KyungWuk/Arknights_Story_Translator/blob/master/Arknights%20Story%20Translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzfywoIswMrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "version 3.4 \n",
        "Based on Arknights Story Translator v7.0 py\n",
        "with Google Cloud Vision API\n",
        "with Google Translation API\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gdVX0vZCSYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose story movie file\n",
        "# This code works on 1480px X 720px vid\n",
        "\n",
        "story_movie_name=\"arknights_2020-08-25-23-03-09.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaFtGoC5SOAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "google_credential_file=\"PUT YOUR GOOGLE CLOUD PLATFORM CREDENTIAL FILE NAME HERE (CREDENTIAL.JSON FILE)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRdcwmb_m4sT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merge_script_num=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeiQTRTsBDVy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89e403c2-61b3-4c99-83e7-0445001c98ab"
      },
      "source": [
        "# Import Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Base directory of google drive\n",
        "base_dir=\"/content/gdrive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcDFFdRjBPYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upgrade google-cloud-vision\n",
        "! pip install --upgrade google-cloud-vision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEXku1bVBpf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set parameters\n",
        "\n",
        "# Black is defined as brightness of 0~50\n",
        "black_error=50 \n",
        "\n",
        "# White is defined as brightness of 205~255\n",
        "white_error=50\n",
        "\n",
        "#\n",
        "lab_error=1000\n",
        "\n",
        "# White pixel is defined as differ between min(BGR) and max(BGR) is under 10 \n",
        "white_gap=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVmo1llqBTeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "from google.cloud import vision\n",
        "from google.cloud import translate_v2 as translate\n",
        "import io\n",
        "import os\n",
        "import six\n",
        "import time\n",
        "\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYljN0tMCkzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions\n",
        "\n",
        "def is_dialogue(frame):\n",
        "  '''is_dialogue(frame)\n",
        "  Check whether given frame has dialogue\n",
        "  by search black and white pixel at given area\n",
        "  '''\n",
        "  global black_error\n",
        "  global white_error\n",
        "  minimum=0+black_error\n",
        "  maximum=255-white_error\n",
        "    \n",
        "  frame=frame[640:720,490:520]\n",
        "  min_bri, max_bri=255,0\n",
        "  for y_axis in frame:\n",
        "    for pixel in y_axis:\n",
        "      bri=sum(pixel)/3\n",
        "      if bri<min_bri:\n",
        "        min_bri=bri\n",
        "      elif max_bri<bri:\n",
        "        max_bri=bri\n",
        "\n",
        "      if min_bri<=minimum and maximum<=max_bri:\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "def is_bg_black(frame):\n",
        "  '''is_bg_black(frame)\n",
        "  Check whether it has black background of dialogue\n",
        "  by check certain positoins pixels are black \n",
        "  '''\n",
        "  global black_error\n",
        "  pointA=sum(frame[719,200])/3\n",
        "  pointB=sum(frame[719,1280])/3\n",
        "  if pointA<black_error and pointB<black_error:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def LAB(frame):\n",
        "  '''LAB(frame)\n",
        "  Amplify white pixels which is pixels of letter\n",
        "  Calculate Letter Amplified Brightness which is sum of brightness of white pixels\n",
        "  '''\n",
        "  global white_error\n",
        "  minimum=255-white_error\n",
        "    \n",
        "  # Letter Amplified Brightness\n",
        "  frame=frame[640:670,485:545]\n",
        "  bri=0\n",
        "  for y_axis in frame:\n",
        "    for pixel in y_axis:\n",
        "      if max(pixel)-min(pixel)<white_gap and minimum<pixel[0] and minimum<pixel[1] or minimum<pixel[2]:\n",
        "        bri+=sum(pixel)/3\n",
        "  return bri\n",
        "\n",
        "def crop_script(frame):\n",
        "  '''crop_script(frame)\n",
        "  Crop certain area with dialogue on frame\n",
        "  '''\n",
        "  return frame[620:720,220:1260]\n",
        "\n",
        "def merge_script(frames):\n",
        "  '''merge_script(frames)\n",
        "  Merge into one file when multiple frame images are given\n",
        "  '''\n",
        "  result=[]\n",
        "  for frame in frames:\n",
        "    for y_axis in frame:\n",
        "      result.append(y_axis)\n",
        "  return np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GXEIGobCa6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open video file\n",
        "cap=cv.VideoCapture(base_dir+story_movie_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7y_WTMdEYd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read first frame and set its values as previous values.\n",
        "# This first frame will not be used.\n",
        "\n",
        "ret,frame=cap.read()\n",
        "\n",
        "prev_frame=frame\n",
        "prev_lab_value=0\n",
        "continuum_warn=False\n",
        "\n",
        "frames=[]\n",
        "scene_num=1\n",
        "left_over=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Sf8yrAFduP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "943e2486-124d-44a3-8cd1-642a0ddfa452"
      },
      "source": [
        "# Collect frames with script and merge 10 script frames to single jpg file \n",
        "while cap.isOpened():\n",
        "\n",
        "  # Read 2nd ~ last frames\n",
        "  ret,frame=cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    # Video is ended and if there're saved frames not merged yet merge them regardless of amount of frames collected\n",
        "    if len(frames)!=0:\n",
        "      script_set=merge_script(frames)\n",
        "      cv.imwrite(base_dir+\"scene %s.jpg\"%scene_num,script_set)\n",
        "      left_over=True\n",
        "    print(\"Final frame\")\n",
        "    break\n",
        "\n",
        "  # If given frame considered to have dialogue (If it has both black-like and white-like pixel)\n",
        "  if is_dialogue(frame)==True:\n",
        "    # Count white pixels (Considered as amount of letters in frame)\n",
        "    lab_value=LAB(frame)\n",
        "    # If white pixels disappeared dramatically (If one dialogue is finished and new dialogue is printing)\n",
        "    if lab_value+lab_error<prev_lab_value:\n",
        "      # Check whether previous frame (last frame before dialogue disappeares) has black background for dialogue for sure\n",
        "      if is_bg_black(prev_frame)==True:\n",
        "        # If it is not continued frame (example: 1st frame and 2nd frame can not contain different-completed dialoogues)\n",
        "        if continuum_warn!=True:\n",
        "\n",
        "          # Crop dialogue part only and save it into list 'frames'\n",
        "          frames.append(crop_script(prev_frame))\n",
        "\n",
        "          # If 'frames' contain enough dialogues merge them and save it as jpg file\n",
        "          if len(frames)==merge_script_num:\n",
        "            script_set=merge_script(frames)\n",
        "            cv.imwrite(base_dir+\"scene %s.jpg\"%scene_num,script_set)\n",
        "            scene_num+=1\n",
        "            frames=[]\n",
        "\n",
        "          # Next frame can not be different-completed dialougue\n",
        "          continuum_warn=True\n",
        "    \n",
        "    # If give frame seems to have dialogue but number of white pixel is ascending (or descend but to small) consider as dialogue is still printing, so neglect it \n",
        "    else:\n",
        "      continuum_warn=False\n",
        "    \n",
        "    # Save current frame as previous frame\n",
        "    prev_frame=frame\n",
        "    prev_lab_value=lab_value\n",
        "  \n",
        "  # It is not considered to contain dialogue neglect this frame so next frame is not continuous\n",
        "  else:\n",
        "    continuum_warn=False\n",
        "\n",
        "# If output says \"Final frame\" crop scripts as jpg image file from video file is completed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final frame\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prVOUQ9v0jYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set application credentials for Google Cloud Vision\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=base_dir+google_credential_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXz7z7ATOP4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Cloud Vision OCR\n",
        "\n",
        "# Code based on\n",
        "# https://cloud.google.com/vision/docs/ocr?hl=ko\n",
        "# https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/vision/cloud-client/detect/detect.py\n",
        "\n",
        "def detect_text(path):\n",
        "  client=vision.ImageAnnotatorClient()\n",
        "\n",
        "  with io.open(path,'rb') as image_file:\n",
        "    content=image_file.read()\n",
        "\n",
        "  image=vision.types.Image(content=content)\n",
        "  \n",
        "  response=client.text_detection(image=image,\n",
        "                                 image_context={\"language_hints\":[\"zh-Hans\"]})\n",
        "  texts=response.text_annotations\n",
        "  #print(\"Texts:\")\n",
        "\n",
        "  result_text=[]\n",
        "  result_pos=[]\n",
        "\n",
        "  for text in texts:\n",
        "\n",
        "    #print('\\n\"{}\"'.format(text.description))\n",
        "    vertices = ([(vertex.x,vertex.y) \n",
        "                for vertex in text.bounding_poly.vertices])\n",
        "    #print('bounds: {}'.format(','.join(vertices)))\n",
        "\n",
        "    result_text.append(text.description)\n",
        "    result_pos.append(vertices)\n",
        "  \n",
        "  if response.error.message:\n",
        "    raise Exception(\n",
        "        '{}\\nFor more info on error messages, check: '\n",
        "        'https://cloud.google.com/apis/design/erros'.format(\n",
        "            response.error.message))\n",
        "  \n",
        "  return result_text, result_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU4-xaT8R5e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Cloud Translation\n",
        "\n",
        "# Code based on\n",
        "# https://cloud.google.com/translate/docs/basic/translating-text#translating_text\n",
        "# https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/translate/cloud-client/snippets.py\n",
        "\n",
        "def translate_text(text, target='ko'):\n",
        "  translate_client=translate.Client()\n",
        "\n",
        "  if isinstance(text, six.binary_type):\n",
        "    text=text.decode('utf-8')\n",
        "  \n",
        "  result=translate_client.translate(text,target_language=target)\n",
        "  return result['translatedText']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIx7ySO-5_Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get text and its positon to discriminate speaker and speech\n",
        "# returns speaker:speech | speaker:speech | speech(dialogue without speaker) format\n",
        "\n",
        "def scriptize(script, pos, layers=merge_script_num):\n",
        "\n",
        "  speaker=['']*layers\n",
        "  speech=['']*layers\n",
        "  \n",
        "  for cursor in range(1,len(script)):\n",
        "    coord=pos[cursor][0][0]\n",
        "    layer=pos[cursor][0][1]//100\n",
        "\n",
        "    if coord<255:\n",
        "      speaker[layer]+=script[cursor]\n",
        "    else:\n",
        "      speech[layer]+=script[cursor]\n",
        "\n",
        "  result=\"\"\n",
        "  for cursor in range (layers):\n",
        "    if speaker[cursor]=='':\n",
        "      result+=(\"%s | \"%(speech[cursor]))\n",
        "    else:\n",
        "      result+=(\"%s:%s | \"%(speaker[cursor],speech[cursor]))\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNWbrE5kF52Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Cloud Vision + Google Cloud Translation\n",
        "\n",
        "# detect_text() -> scriptize() -> translate_text()\n",
        "# [\"a\", \"sth\", ...],[[1,1], [1,2], ...] -> \"a:sth ...\" -> \"someone:says | ...\"\n",
        "\n",
        "if left_over==False:\n",
        "  scene_num-=1\n",
        "\n",
        "txt_dir=(base_dir+story_movie_name).replace('.mp4','-tr.txt')\n",
        "result_txt=open(txt_dir,'w')\n",
        "\n",
        "for file_num in range (1, scene_num):\n",
        "  file_dir=base_dir+(\"scene %s.jpg\"%file_num)\n",
        "  script, pos=detect_text(file_dir)\n",
        "  scriptized=scriptize(script,pos)\n",
        "  translated=translate_text(scriptized)\n",
        "\n",
        "  # after texts are returned from scriptize() there will be 10 '|' (which is normally not used in dialogues)\n",
        "  # Split dialogues on '|' and make 11 parts\n",
        "  # if translated result contains all 10 '|', last dialogue and speeker will be just '' but sometimes nuber of '|' does not match so last part needs to be saved for awhile\n",
        "\n",
        "  scr_zh=scriptized.split('|')\n",
        "  scr_zh.pop(-1)\n",
        "  scr_ko=translated.split('|')\n",
        "  temp=scr_ko.pop(-1)\n",
        "  temp_check=temp.replace(' ','')\n",
        "\n",
        "  stack=1\n",
        "  while len(scr_ko)!=merge_script_num:\n",
        "    if len(scr_ko)<merge_script_num:\n",
        "      if stack==1 and len(temp_check)>0:\n",
        "        scr_ko.append(temp)\n",
        "        stack-=1\n",
        "        \n",
        "        temp_check=\"\"\n",
        "      else:\n",
        "        scr_ko.append(\"번역 결과 병합 발생 경고 %s회\"%stack)\n",
        "    else:\n",
        "      scr_ko[-2]+=scr_ko[-1]+(\"번역 결과 개행 발생 경고 %s회\"%stack)\n",
        "      scr_ko.pop(-1)\n",
        "    stack+=1\n",
        "\n",
        "  # save the result as txt file\n",
        "  for line in range (merge_script_num):\n",
        "    result_txt.write(scr_zh[line]+\"\\n\")\n",
        "    result_txt.write(scr_ko[line]+\"\\n\\n\")\n",
        "  time.sleep(1.001)\n",
        "\n",
        "# Do the same thing but if there is script images which has not 10 scripts (left over)\n",
        "if left_over==True:\n",
        "  file_dir=base_dir+(\"scene %s.jpg\"%(scene_num))\n",
        "  script, pos=detect_text(file_dir)\n",
        "  scriptized=scriptize(script,pos)\n",
        "  translated=translate_text(scriptized)\n",
        "\n",
        "  scr_zh=scriptized.split('|')\n",
        "  scr_zh.pop(-1)\n",
        "\n",
        "  scr_ko=translated.split('|')\n",
        "  scr_ko.pop(-1)\n",
        "\n",
        "  stack=1\n",
        "  while len(scr_ko)!=len(scr_zh):\n",
        "    if len(scr_ko)<merge_script_num:\n",
        "      scr_ko.append(\"번역 결과 병합 발생 경고 %s회\"%stack)\n",
        "    else:\n",
        "      scr_ko[-2]+=scr_ko[-1]+(\"번역 결과 개행 발생 경고 %s회\"%stack)\n",
        "      scr_ko.pop(-1)\n",
        "    stack+=1\n",
        "\n",
        "  for line in range (len(scr_zh)):\n",
        "    result_txt.write(scr_zh[line]+\"\\n\")\n",
        "    result_txt.write(scr_ko[line]+\"\\n\\n\")\n",
        "\n",
        "# close the text file\n",
        "result_txt.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}